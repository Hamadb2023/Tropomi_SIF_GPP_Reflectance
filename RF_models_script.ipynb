{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chief-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "#########                                                              #############\n",
    "#########   Establishing the four Random Forest Model for understang   ##############\n",
    "########## the synergy between SIF, reflectance and vegetation index   #############\n",
    "#########                                                              #############\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "specific-respondent",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import required libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "from datetime import datetime, timedelta \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "import scipy\n",
    "import math\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score, mean_absolute_error\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels as sm\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "double-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controling the label, font, axes and legend sizes\n",
    "#plt.rc('font', size=16, weight='bold') #controls default text sizesns.set_style('whitegrid')\n",
    "plt.rc('font', size=16) #controls default text sizesns.set_style('whitegrid')\n",
    "plt.rc('xtick', labelsize=20) #fontsize of the x tick labels\n",
    "plt.rc('ytick', labelsize=20) #fontsize of the y tick labels\n",
    "plt.rc('legend', fontsize=20) #fontsize of the legend\n",
    "plt.rc('axes', titlesize=20) #fontsize of the title\n",
    "plt.rc('axes', labelsize=20) #fontsize of the x and y labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "horizontal-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your working directory\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir(\"D:/SIF_GPP_PRI_Tropomi/Linear_Regression_output/LR_Stats/LAST_testing/figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "possible-links",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sif</th>\n",
       "      <th>sif_err</th>\n",
       "      <th>sif_relative</th>\n",
       "      <th>dcSIF</th>\n",
       "      <th>cloud_fraction</th>\n",
       "      <th>sza</th>\n",
       "      <th>vza</th>\n",
       "      <th>phase_angle</th>\n",
       "      <th>daily_correction_factor</th>\n",
       "      <th>lat</th>\n",
       "      <th>...</th>\n",
       "      <th>NEE_VUT_REF</th>\n",
       "      <th>PPFD_OUT</th>\n",
       "      <th>TA_F</th>\n",
       "      <th>VPD_F</th>\n",
       "      <th>Year</th>\n",
       "      <th>DoY</th>\n",
       "      <th>saveGPP</th>\n",
       "      <th>IGBP_site</th>\n",
       "      <th>Site</th>\n",
       "      <th>DOY</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>-0.1047</td>\n",
       "      <td>0.2426</td>\n",
       "      <td>-0.4586</td>\n",
       "      <td>-0.0265</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>66.599998</td>\n",
       "      <td>24.200001</td>\n",
       "      <td>-78.300003</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>51.301701</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>737098</td>\n",
       "      <td>1.574183</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-14</th>\n",
       "      <td>0.4536</td>\n",
       "      <td>0.2607</td>\n",
       "      <td>1.6363</td>\n",
       "      <td>0.1202</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>64.400002</td>\n",
       "      <td>50.799999</td>\n",
       "      <td>91.500000</td>\n",
       "      <td>0.2651</td>\n",
       "      <td>51.308800</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>737105</td>\n",
       "      <td>1.546119</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-16</th>\n",
       "      <td>0.2810</td>\n",
       "      <td>0.2599</td>\n",
       "      <td>1.0219</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>64.199997</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>-58.700001</td>\n",
       "      <td>0.2737</td>\n",
       "      <td>51.270401</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>737107</td>\n",
       "      <td>1.833989</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-16</th>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.2675</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>64.300003</td>\n",
       "      <td>15.300000</td>\n",
       "      <td>-58.799999</td>\n",
       "      <td>0.2736</td>\n",
       "      <td>51.332802</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>737107</td>\n",
       "      <td>1.833989</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-18</th>\n",
       "      <td>0.3418</td>\n",
       "      <td>0.2953</td>\n",
       "      <td>0.8903</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>62.900002</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>-78.599998</td>\n",
       "      <td>0.2702</td>\n",
       "      <td>51.337101</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018</td>\n",
       "      <td>737109</td>\n",
       "      <td>1.639252</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-25</th>\n",
       "      <td>0.3064</td>\n",
       "      <td>0.3227</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>35.400002</td>\n",
       "      <td>85.400002</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>64.242798</td>\n",
       "      <td>...</td>\n",
       "      <td>125.159621</td>\n",
       "      <td>41.86</td>\n",
       "      <td>7.238958</td>\n",
       "      <td>0.580417</td>\n",
       "      <td>2020</td>\n",
       "      <td>738059</td>\n",
       "      <td>4.102004</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-03</th>\n",
       "      <td>-0.0848</td>\n",
       "      <td>0.2930</td>\n",
       "      <td>-0.3594</td>\n",
       "      <td>-0.0248</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>68.699997</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>-67.500000</td>\n",
       "      <td>0.2926</td>\n",
       "      <td>64.250198</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>738067</td>\n",
       "      <td>3.078926</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-03</th>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.2963</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>68.699997</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>-67.599998</td>\n",
       "      <td>0.2925</td>\n",
       "      <td>64.238403</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>738067</td>\n",
       "      <td>3.078926</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-03</th>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.2966</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>68.699997</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>-67.300003</td>\n",
       "      <td>0.2926</td>\n",
       "      <td>64.261803</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>738067</td>\n",
       "      <td>3.078926</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-03</th>\n",
       "      <td>-0.1585</td>\n",
       "      <td>0.2851</td>\n",
       "      <td>-0.7273</td>\n",
       "      <td>-0.0464</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>68.800003</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>-67.500000</td>\n",
       "      <td>0.2925</td>\n",
       "      <td>64.296799</td>\n",
       "      <td>...</td>\n",
       "      <td>37.084010</td>\n",
       "      <td>113.17</td>\n",
       "      <td>7.615417</td>\n",
       "      <td>0.329167</td>\n",
       "      <td>2020</td>\n",
       "      <td>738067</td>\n",
       "      <td>3.078926</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24476 rows × 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               sif  sif_err  sif_relative   dcSIF  cloud_fraction        sza  \\\n",
       "Timestamp                                                                      \n",
       "2018-02-07 -0.1047   0.2426       -0.4586 -0.0265          0.0000  66.599998   \n",
       "2018-02-14  0.4536   0.2607        1.6363  0.1202          0.0000  64.400002   \n",
       "2018-02-16  0.2810   0.2599        1.0219  0.0769          0.0450  64.199997   \n",
       "2018-02-16  0.0293   0.2675        0.0986  0.0080          0.0056  64.300003   \n",
       "2018-02-18  0.3418   0.2953        0.8903  0.0924          0.0196  62.900002   \n",
       "...            ...      ...           ...     ...             ...        ...   \n",
       "2020-09-25  0.3064   0.3227        0.9896  0.0956          0.0433  65.500000   \n",
       "2020-10-03 -0.0848   0.2930       -0.3594 -0.0248          0.0000  68.699997   \n",
       "2020-10-03  0.0474   0.2963        0.1945  0.0139          0.0000  68.699997   \n",
       "2020-10-03  0.0913   0.2966        0.3738  0.0267          0.0000  68.699997   \n",
       "2020-10-03 -0.1585   0.2851       -0.7273 -0.0464          0.0238  68.800003   \n",
       "\n",
       "                  vza  phase_angle  daily_correction_factor        lat  ...  \\\n",
       "Timestamp                                                               ...   \n",
       "2018-02-07  24.200001   -78.300003                   0.2535  51.301701  ...   \n",
       "2018-02-14  50.799999    91.500000                   0.2651  51.308800  ...   \n",
       "2018-02-16  15.300000   -58.700001                   0.2737  51.270401  ...   \n",
       "2018-02-16  15.300000   -58.799999                   0.2736  51.332802  ...   \n",
       "2018-02-18  30.600000   -78.599998                   0.2702  51.337101  ...   \n",
       "...               ...          ...                      ...        ...  ...   \n",
       "2020-09-25  35.400002    85.400002                   0.3118  64.242798  ...   \n",
       "2020-10-03   2.600000   -67.500000                   0.2926  64.250198  ...   \n",
       "2020-10-03   2.300000   -67.599998                   0.2925  64.238403  ...   \n",
       "2020-10-03   2.900000   -67.300003                   0.2926  64.261803  ...   \n",
       "2020-10-03   2.600000   -67.500000                   0.2925  64.296799  ...   \n",
       "\n",
       "            NEE_VUT_REF  PPFD_OUT      TA_F     VPD_F  Year     DoY   saveGPP  \\\n",
       "Timestamp                                                                       \n",
       "2018-02-07          NaN       NaN       NaN       NaN  2018  737098  1.574183   \n",
       "2018-02-14          NaN       NaN       NaN       NaN  2018  737105  1.546119   \n",
       "2018-02-16          NaN       NaN       NaN       NaN  2018  737107  1.833989   \n",
       "2018-02-16          NaN       NaN       NaN       NaN  2018  737107  1.833989   \n",
       "2018-02-18          NaN       NaN       NaN       NaN  2018  737109  1.639252   \n",
       "...                 ...       ...       ...       ...   ...     ...       ...   \n",
       "2020-09-25   125.159621     41.86  7.238958  0.580417  2020  738059  4.102004   \n",
       "2020-10-03          NaN       NaN       NaN       NaN  2020  738067  3.078926   \n",
       "2020-10-03          NaN       NaN       NaN       NaN  2020  738067  3.078926   \n",
       "2020-10-03          NaN       NaN       NaN       NaN  2020  738067  3.078926   \n",
       "2020-10-03    37.084010    113.17  7.615417  0.329167  2020  738067  3.078926   \n",
       "\n",
       "            IGBP_site  Site  DOY  \n",
       "Timestamp                         \n",
       "2018-02-07          5     0   38  \n",
       "2018-02-14          5     0   45  \n",
       "2018-02-16          5     0   47  \n",
       "2018-02-16          5     0   47  \n",
       "2018-02-18          5     0   49  \n",
       "...               ...   ...  ...  \n",
       "2020-09-25          3    39  269  \n",
       "2020-10-03          3    39  277  \n",
       "2020-10-03          3    39  277  \n",
       "2020-10-03          3    39  277  \n",
       "2020-10-03          3    39  277  \n",
       "\n",
       "[24476 rows x 72 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load your merged data set\n",
    "\n",
    "df_merge = pd.read_csv('D:\\LCC/DataGPPfiltered.csv')\n",
    "\n",
    "# convert your datetime into datetime format and set it as index \n",
    "df_merge['Timestamp'] = pd.to_datetime(df_merge['Timestamp'], format ='%m/%d/%Y')\n",
    "\n",
    "#Filtering based on the distance (<=5 km) and cloud fraction (<=15%)\n",
    "df_merge = df_merge[(df_merge['distance']<= 5)&(df_merge['cloud_fraction']<=0.15)]\n",
    "\n",
    "# Outliers filtering\n",
    "df_merge = df_merge[(df_merge['Err_mesure']<=0.15)&(df_merge['Err_mesure']>=-0.15)]\n",
    "\n",
    "# Drop your columns \n",
    "df_merge['Timestamp'] = df_merge.set_index(df_merge['Timestamp'], inplace = True)\n",
    "df_merge = df_merge.drop(columns = ['Timestamp'])\n",
    "\n",
    "# Convert categorical variables as numeric, Biomes and Sites.\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "\n",
    "# label_encoder object\n",
    "label_encoder =LabelEncoder()\n",
    "# Encode labels in column. \n",
    "df_merge['IGBP_site']= label_encoder.fit_transform(df_merge['Biome_site'])\n",
    "df_merge['Site']= label_encoder.fit_transform(df_merge['Site_name'])\n",
    "\n",
    "#Rename daily averaged SIF\n",
    "df_merge.rename(columns={'daily_averaged_SIF':'SIF_Daily'}, inplace = True)\n",
    "\n",
    "# convert site name to liste and sort the data frame\n",
    "listSites = df_merge[\"Site_name\"].unique().tolist()\n",
    "listSites = sorted(listSites)\n",
    "\n",
    "# replace null GPP values as nan\n",
    "df_merge['GPP'][df_merge['GPP']==0] = np.nan\n",
    "\n",
    "#Drop nan values \n",
    "df_merge.dropna(subset = ['GPP'], inplace = True)\n",
    "\n",
    "#get dayofyear from dataframe index\n",
    "df_merge['DOY'] = df_merge.index.dayofyear\n",
    "\n",
    "df_merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "italic-shark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B1</th>\n",
       "      <th>B2</th>\n",
       "      <th>B3</th>\n",
       "      <th>B4</th>\n",
       "      <th>B5</th>\n",
       "      <th>B6</th>\n",
       "      <th>B7</th>\n",
       "      <th>B8</th>\n",
       "      <th>B9</th>\n",
       "      <th>B11</th>\n",
       "      <th>...</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>NIRv</th>\n",
       "      <th>PRI13</th>\n",
       "      <th>IGBP_site</th>\n",
       "      <th>Year</th>\n",
       "      <th>day</th>\n",
       "      <th>DoY</th>\n",
       "      <th>Site_name</th>\n",
       "      <th>Site_palette</th>\n",
       "      <th>Biome_site</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>434</td>\n",
       "      <td>2080</td>\n",
       "      <td>249.0</td>\n",
       "      <td>491</td>\n",
       "      <td>2611</td>\n",
       "      <td>1530</td>\n",
       "      <td>852</td>\n",
       "      <td>217</td>\n",
       "      <td>338.0</td>\n",
       "      <td>388</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.261998</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>737097</td>\n",
       "      <td>737098</td>\n",
       "      <td>BE-Bra</td>\n",
       "      <td>BE-Bra</td>\n",
       "      <td>MF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-14</th>\n",
       "      <td>506</td>\n",
       "      <td>2213</td>\n",
       "      <td>239.0</td>\n",
       "      <td>539</td>\n",
       "      <td>2834</td>\n",
       "      <td>1843</td>\n",
       "      <td>1113</td>\n",
       "      <td>214</td>\n",
       "      <td>333.0</td>\n",
       "      <td>495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.267298</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>737104</td>\n",
       "      <td>737105</td>\n",
       "      <td>BE-Bra</td>\n",
       "      <td>BE-Bra</td>\n",
       "      <td>MF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-16</th>\n",
       "      <td>506</td>\n",
       "      <td>2213</td>\n",
       "      <td>239.0</td>\n",
       "      <td>539</td>\n",
       "      <td>2834</td>\n",
       "      <td>1843</td>\n",
       "      <td>1113</td>\n",
       "      <td>214</td>\n",
       "      <td>333.0</td>\n",
       "      <td>495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.267298</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>737106</td>\n",
       "      <td>737107</td>\n",
       "      <td>BE-Bra</td>\n",
       "      <td>BE-Bra</td>\n",
       "      <td>MF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-16</th>\n",
       "      <td>506</td>\n",
       "      <td>2213</td>\n",
       "      <td>239.0</td>\n",
       "      <td>539</td>\n",
       "      <td>2834</td>\n",
       "      <td>1843</td>\n",
       "      <td>1113</td>\n",
       "      <td>214</td>\n",
       "      <td>333.0</td>\n",
       "      <td>495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.267298</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>737106</td>\n",
       "      <td>737107</td>\n",
       "      <td>BE-Bra</td>\n",
       "      <td>BE-Bra</td>\n",
       "      <td>MF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-18</th>\n",
       "      <td>414</td>\n",
       "      <td>1755</td>\n",
       "      <td>185.0</td>\n",
       "      <td>386</td>\n",
       "      <td>1864</td>\n",
       "      <td>1386</td>\n",
       "      <td>646</td>\n",
       "      <td>813</td>\n",
       "      <td>1133.0</td>\n",
       "      <td>924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.208607</td>\n",
       "      <td>0.026</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>737108</td>\n",
       "      <td>737109</td>\n",
       "      <td>BE-Bra</td>\n",
       "      <td>BE-Bra</td>\n",
       "      <td>MF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-25</th>\n",
       "      <td>153</td>\n",
       "      <td>470</td>\n",
       "      <td>127.0</td>\n",
       "      <td>191</td>\n",
       "      <td>398</td>\n",
       "      <td>188</td>\n",
       "      <td>104</td>\n",
       "      <td>1110</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.043399</td>\n",
       "      <td>0.093</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>738058</td>\n",
       "      <td>738059</td>\n",
       "      <td>SE-Svb</td>\n",
       "      <td>SE-Svb</td>\n",
       "      <td>ENF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-03</th>\n",
       "      <td>153</td>\n",
       "      <td>470</td>\n",
       "      <td>127.0</td>\n",
       "      <td>191</td>\n",
       "      <td>398</td>\n",
       "      <td>188</td>\n",
       "      <td>104</td>\n",
       "      <td>1110</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.043399</td>\n",
       "      <td>0.093</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>738066</td>\n",
       "      <td>738067</td>\n",
       "      <td>SE-Svb</td>\n",
       "      <td>SE-Svb</td>\n",
       "      <td>ENF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-03</th>\n",
       "      <td>153</td>\n",
       "      <td>470</td>\n",
       "      <td>127.0</td>\n",
       "      <td>191</td>\n",
       "      <td>398</td>\n",
       "      <td>188</td>\n",
       "      <td>104</td>\n",
       "      <td>1110</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.043399</td>\n",
       "      <td>0.093</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>738066</td>\n",
       "      <td>738067</td>\n",
       "      <td>SE-Svb</td>\n",
       "      <td>SE-Svb</td>\n",
       "      <td>ENF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-03</th>\n",
       "      <td>153</td>\n",
       "      <td>470</td>\n",
       "      <td>127.0</td>\n",
       "      <td>191</td>\n",
       "      <td>398</td>\n",
       "      <td>188</td>\n",
       "      <td>104</td>\n",
       "      <td>1110</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.043399</td>\n",
       "      <td>0.093</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>738066</td>\n",
       "      <td>738067</td>\n",
       "      <td>SE-Svb</td>\n",
       "      <td>SE-Svb</td>\n",
       "      <td>ENF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-03</th>\n",
       "      <td>153</td>\n",
       "      <td>470</td>\n",
       "      <td>127.0</td>\n",
       "      <td>191</td>\n",
       "      <td>398</td>\n",
       "      <td>188</td>\n",
       "      <td>104</td>\n",
       "      <td>1110</td>\n",
       "      <td>1023.0</td>\n",
       "      <td>906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.043399</td>\n",
       "      <td>0.093</td>\n",
       "      <td>3</td>\n",
       "      <td>2020</td>\n",
       "      <td>738066</td>\n",
       "      <td>738067</td>\n",
       "      <td>SE-Svb</td>\n",
       "      <td>SE-Svb</td>\n",
       "      <td>ENF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24445 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             B1    B2     B3   B4    B5    B6    B7    B8      B9  B11  ...  \\\n",
       "Timestamp                                                               ...   \n",
       "2018-02-07  434  2080  249.0  491  2611  1530   852   217   338.0  388  ...   \n",
       "2018-02-14  506  2213  239.0  539  2834  1843  1113   214   333.0  495  ...   \n",
       "2018-02-16  506  2213  239.0  539  2834  1843  1113   214   333.0  495  ...   \n",
       "2018-02-16  506  2213  239.0  539  2834  1843  1113   214   333.0  495  ...   \n",
       "2018-02-18  414  1755  185.0  386  1864  1386   646   813  1133.0  924  ...   \n",
       "...         ...   ...    ...  ...   ...   ...   ...   ...     ...  ...  ...   \n",
       "2020-09-25  153   470  127.0  191   398   188   104  1110  1023.0  906  ...   \n",
       "2020-10-03  153   470  127.0  191   398   188   104  1110  1023.0  906  ...   \n",
       "2020-10-03  153   470  127.0  191   398   188   104  1110  1023.0  906  ...   \n",
       "2020-10-03  153   470  127.0  191   398   188   104  1110  1023.0  906  ...   \n",
       "2020-10-03  153   470  127.0  191   398   188   104  1110  1023.0  906  ...   \n",
       "\n",
       "             NDVI      NIRv  PRI13  IGBP_site  Year     day     DoY  \\\n",
       "Timestamp                                                             \n",
       "2018-02-07  0.655  0.261998 -0.090          5  2018  737097  737098   \n",
       "2018-02-14  0.628  0.267298 -0.091          5  2018  737104  737105   \n",
       "2018-02-16  0.628  0.267298 -0.091          5  2018  737106  737107   \n",
       "2018-02-16  0.628  0.267298 -0.091          5  2018  737106  737107   \n",
       "2018-02-18  0.618  0.208607  0.026          5  2018  737108  737109   \n",
       "...           ...       ...    ...        ...   ...     ...     ...   \n",
       "2020-09-25  0.509  0.043399  0.093          3  2020  738058  738059   \n",
       "2020-10-03  0.509  0.043399  0.093          3  2020  738066  738067   \n",
       "2020-10-03  0.509  0.043399  0.093          3  2020  738066  738067   \n",
       "2020-10-03  0.509  0.043399  0.093          3  2020  738066  738067   \n",
       "2020-10-03  0.509  0.043399  0.093          3  2020  738066  738067   \n",
       "\n",
       "            Site_name  Site_palette  Biome_site  \n",
       "Timestamp                                        \n",
       "2018-02-07     BE-Bra        BE-Bra          MF  \n",
       "2018-02-14     BE-Bra        BE-Bra          MF  \n",
       "2018-02-16     BE-Bra        BE-Bra          MF  \n",
       "2018-02-16     BE-Bra        BE-Bra          MF  \n",
       "2018-02-18     BE-Bra        BE-Bra          MF  \n",
       "...               ...           ...         ...  \n",
       "2020-09-25     SE-Svb        SE-Svb         ENF  \n",
       "2020-10-03     SE-Svb        SE-Svb         ENF  \n",
       "2020-10-03     SE-Svb        SE-Svb         ENF  \n",
       "2020-10-03     SE-Svb        SE-Svb         ENF  \n",
       "2020-10-03     SE-Svb        SE-Svb         ENF  \n",
       "\n",
       "[24445 rows x 23 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate a new data set based on the correlation matrix results to establish the RF models\n",
    "\n",
    "columns = ['B1','B2','B3','B4','B5','B6','B7','B8','B9','B11','B13',\n",
    "           'SIF_Daily', 'GPP', 'NDVI', 'NIRv','PRI13','IGBP_site','Year','day','DoY','Site_name',\n",
    "           'Site_palette','Biome_site']\n",
    "\n",
    "Data = df_merge[columns]\n",
    "#Data = FR_Fon[columns]\n",
    "Data= Data.dropna(axis =0)\n",
    "#Data = Data[(Data['IGBP_LC5km']=='CRO')]\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "floral-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparation for the random forest model setting\n",
    "#get the required libraries \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#select your explanatory variables\n",
    "\n",
    "columns = ['B1','B2','B3','B4','B5','B6','B7','B8','B9','B11','B13',\n",
    "           'SIF_Daily', 'NDVI', 'NIRv','PRI13','IGBP_site','Year','day','DoY','Site_name','Biome_site']\n",
    "\n",
    "# select your target variable\n",
    "columntarg = ['GPP']\n",
    "data = Data[columns]\n",
    "#data['B15'] =data['B15'].astype(float)\n",
    "target = Data[columntarg]\n",
    "# split your dataset into training set and testing set: 80% for training and 20% for testing the model \n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size= 0.20, random_state= 42)\n",
    "\n",
    "#################################################################################################################################\n",
    "#create a new data frame for testing data as you will need it to test your model not only on all data pooled across all sites but also based on each site and each PFT\n",
    "df = pd.concat([data_test, target_test], axis =1)\n",
    "\n",
    "#df.to_csv('data_testing2.csv') #uncomment this line to save your testing data in your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "third-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  4.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 40, 'bootstrap': False}  \n",
      "\n",
      "RF_model_score=0.911012\n",
      "Wall time: 4min 22s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#############################################################################################################################\n",
    "#### Establishing the four RF models    ###################################################################################\n",
    "##########################################################################################################################\n",
    "columns = ['B1','B2','B3','B4','B5','B6','B7','B8','B9','B11','B13'] # uncomment this line to run your RF-R model\n",
    "#columns = ['SIF_Daily','B1','B2','B3','B4','B5','B6','B7','B8','B9','B11','B13'] # uncomment this line to run your RF-SIF-R model\n",
    "#columns = ['SIF_Daily','B1','B2','B3','B4','B5','B6','B7','B8','B9','B11','B13', 'IGBP_site']\n",
    "#columns = ['SIF_Daily','NIRv','NDVI','PRI13']  # # uncomment this line to run your RF-SIF-VI model\n",
    "\n",
    "######################################################################################################################\n",
    "columntarg = ['GPP']\n",
    "data = Data[columns]\n",
    "target = Data[columntarg]\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size= 0.20, random_state= 42)\n",
    "\n",
    "\n",
    "## Importing Random Forest regressor from the sklearn.ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "## Use Randomized SearchCV to tune your model parameters\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "Randomized_GridCV = {'bootstrap': [True, False],# method used to sample data points\n",
    "            'max_depth': [5, 6, 7, 8, 9,10, 15, 20, 30, 40, 50, 60,\n",
    "                        70, 80, 90, 100, 110,120], # maximum number of levels allowed in each decision tree\n",
    "            'max_features': ['log2', 'sqrt','auto'], # number of features in consideration at every split\n",
    "            'min_samples_leaf': [1, 2, 3, 4, 5, 10], # minimum sample number that can be stored in a leaf node\n",
    "            'min_samples_split': [1, 2, 6, 10], # minimum sample number to split a node\n",
    "            'n_estimators': [2, 5, 10, 15, 20, 20, 30, 50, 80, 100, 150, 200]}, # number of trees in the random forest\n",
    "\n",
    "rf_random = RandomizedSearchCV(cv=10, estimator=RandomForestRegressor(), n_iter=20,\n",
    "                   n_jobs=-1,\n",
    "                   param_distributions= Randomized_GridCV,\n",
    "                   random_state= 42, verbose=2)\n",
    "# Fit your random forest model\n",
    "\n",
    "rf_random.fit(data_train, target_train)\n",
    "\n",
    "# print the best parameters\n",
    "print ('Best Parameters: ', rf_random.best_params_, ' \\n')\n",
    "\n",
    "# use the best parameters for prediction\n",
    "\n",
    "best_model = rf_random.best_estimator_\n",
    "\n",
    "GPP_RF = best_model.predict(data_test)\n",
    "print(\"RF_model_score=%.6f\"% best_model.score(data_train, target_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "grateful-stomach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_Prediction_score=0.861017\n",
      "RF_model_score=0.912749\n",
      "Adjusted R_squared: 0.8607038891651133\n",
      "RMSE: 1.6796073552656978\n",
      "MAE: 0.9412311967326992\n",
      "Explained_variance_score: 0.8610316748006382\n",
      "Wall time: 18.7 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "#############################################################################################################################\n",
    "#### Establishing the four RF models    ###################################################################################\n",
    "##########################################################################################################################\n",
    "columns = ['B1','B2','B3','B4','B5','B6','B7','B8','B9','B11','B13'] # uncomment this line to run your RF-R model\n",
    "#columns = ['SIF_Daily','B1','B2','B3','B4','B5','B6','B7','B8','B9','B11','B13'] # uncomment this line to run your RF-SIF-R model\n",
    "#columns = ['SIF_Daily','B1','B2','B3','B4','B5','B6','B7','B8','B9','B11','B13', 'IGBP_site']\n",
    "#columns = ['SIF_Daily','NIRv','NDVI','PRI13']  # # uncomment this line to run your RF-SIF-VI model\n",
    "\n",
    "######################################################################################################################\n",
    "\n",
    "columntarg = ['GPP']\n",
    "data = Data[columns]\n",
    "#data['B15'] =data['B15'].astype(float)\n",
    "target = Data[columntarg]\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(data, target, test_size= 0.20, random_state= 42)\n",
    "\n",
    "## Importing Random Forest Classifier from the sklearn.ensemble\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# use the best parameters to make model prediction\n",
    "best_model = RandomForestRegressor(n_estimators = 200, min_samples_split = 10, min_samples_leaf= 1, max_features = 'sqrt', max_depth= 40, bootstrap= False) \n",
    "#best_model = RandomForestRegressor(n_estimators = 200, min_samples_split = 2, min_samples_leaf= 1, max_features = 'sqrt', max_depth= 110, bootstrap=False) \n",
    "\n",
    "\n",
    "best_model.fit(data_train, target_train)\n",
    "\n",
    "\n",
    "GPP_RF = best_model.predict(data_test)\n",
    "\n",
    "print(\"RF_Prediction_score=%.6f\"% best_model.score(data_test, target_test))\n",
    "print(\"RF_model_score=%.6f\"% best_model.score(data_train, target_train))\n",
    "#print(\"params:\", regr_rf.estimator_params)\n",
    "#print(\"alpha:\", regr_rf.ccp_alpha)\n",
    "\n",
    "# Model Evaluation Parameters\n",
    "\n",
    "MSE = mean_squared_error(target_test,GPP_RF)\n",
    "RMSE = math.sqrt(MSE)\n",
    "MAE = mean_absolute_error(target_test, GPP_RF)\n",
    "EVS = explained_variance_score(target_test, GPP_RF, multioutput='variance_weighted')\n",
    "R_squared = best_model.score(data_test, target_test)\n",
    "\n",
    "# Calculate the adjusted R-squared\n",
    "adjusted_R = 1 - (1-best_model.score(data_test, target_test))*(len(target_test)-1)/(len(target_test)-data_test.shape[1]-1)\n",
    "\n",
    "print(\"Adjusted R_squared:\", adjusted_R)\n",
    "print(\"RMSE:\",RMSE)\n",
    "print(\"MAE:\", MAE)\n",
    "print(\"Explained_variance_score:\",EVS )\n",
    "\n",
    "target_test['GPP_RF_R'] = best_model.predict(data_test)\n",
    "\n",
    "#target_test.to_csv('GPP_Predicted_RF_R.csv') # uncomment this line to record your model GPP prediction in your working directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "authorized-playing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 147 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variables</th>\n",
       "      <th>Importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B8</td>\n",
       "      <td>0.047085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B9</td>\n",
       "      <td>0.055081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B11</td>\n",
       "      <td>0.064165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B3</td>\n",
       "      <td>0.067674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B7</td>\n",
       "      <td>0.069444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B4</td>\n",
       "      <td>0.070338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B6</td>\n",
       "      <td>0.076966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B5</td>\n",
       "      <td>0.081959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B13</td>\n",
       "      <td>0.098853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B1</td>\n",
       "      <td>0.131944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B2</td>\n",
       "      <td>0.236491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variables  Importances\n",
       "7         B8     0.047085\n",
       "8         B9     0.055081\n",
       "9        B11     0.064165\n",
       "2         B3     0.067674\n",
       "6         B7     0.069444\n",
       "3         B4     0.070338\n",
       "5         B6     0.076966\n",
       "4         B5     0.081959\n",
       "10       B13     0.098853\n",
       "0         B1     0.131944\n",
       "1         B2     0.236491"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#######################################################################################################\n",
    "########### Determining the feature relative importance        #######################################\n",
    "######################################################################################################\n",
    "# Get your feature_importances and mean permutation importances from the best model RF fit\n",
    "\n",
    "#importances = best_model.feature_importances_\n",
    "importances = best_model.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)\n",
    "features = data_train.columns\n",
    "imp = []\n",
    "\n",
    "dat = pd.DataFrame()\n",
    "imp.append(importances)\n",
    "########################################################################################################################\n",
    "\n",
    "Dat= pd.DataFrame(imp).transpose()\n",
    "\n",
    "#Dat = pd.concat([dfm, dfmean, std], axis =1)\n",
    "Dat.columns = ['Importances']\n",
    "Dat.index = data_train.columns\n",
    "Dat.index.name ='Variables'\n",
    "\n",
    "#rename columns \n",
    "#Dat.rename(columns ={'PRI13':'PRI', 'IGBP_LCnum':'IGBP_Biome'})\n",
    "Dat.rename(index={'PRI13':'PRI','IGBP_site':'IGBP_Biome','SIF_Daily':'SIF Daily', 'GPP':'GPP'}, inplace = True)\n",
    "Dat.reset_index(inplace = True)\n",
    "\n",
    "Dat.sort_values(by= ['Importances',], inplace= True )\n",
    "\n",
    "#print(Dat.index.name)\n",
    "#Dat.to_csv('RF_R_Importances.csv') # uncomment this line to record your feature relative importance into your working directory\n",
    "Dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-quantum",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
